---
title: "Revision"
author: "Erik Ø. Sørensen"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output:
  html_document:
    toc: true
    toc_depth: 2
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#source(here::here("packages.R"))
#source(here::here("functions.R"))
tar_load(mmzame_decisions)
```

This document is structured to answer the concerns of the referees with
respect to the empirical work. The plan is to incorporate what we need
in the main analysis (possibly mostly in an appendix), this document is more 
for our own internal benefit.

# Any impact of the observer treatment?

Reviewer 2 writes that:

> Given that it does not provide any testable implications of your
> theory, I agree that analysis of these treatment will not give any
> useful information and it should be excluded. If this treatment is
> conducted at the end in all the sessions, it could not create any
> issue in the preceding decisions. However, if the order of Observer
> treatment varies across sessions, you can show that there is no
> significant difference in the distributions of the decisions before
> and after the Observer treatment.

The order we decided on for the 4 treatments was to always first run the "Social
Risk" treatment, and then the other 3 treatments in randomized order. So we have
data on the 3 treatments in 6 different sequences. We can use this to create a
test based on the share allocated to self in the "Social Choice" treatment (by
sequence) and similarly the share allocated to the cheapest asset in the
"Personal Risk" treatment.

```{r echo=FALSE, message=FALSE, warning=FALSE}
# To implement, first create a data set with the individual orders of treatments and
# join to decisions:
tar_load(mmzame_decisions_alltreatments)
sequence <- mmzame_decisions_alltreatments %>% 
  filter(round==1) %>%
  pivot_wider(id_cols = id, names_from = treatment, values_from = phase, names_prefix = "seq_")
ordered_means <- mmzame_decisions_alltreatments %>% 
  left_join(sequence) %>% 
  mutate(DRO_order = paste(seq_dictator, seq_risk, seq_observer, sep=","), 
         share_self = y/(y+x),
         share_cheapest = if_else(maxy>maxx, y/(y+x), x/(y+x))) %>%
  group_by(id, DRO_order, treatment) %>%
  summarize(share_self = mean(share_self),
            share_cheapest = mean(share_cheapest)) %>%
  ungroup()
```
If we look at the selfish individuals and proposition 3, does the test 
outcome vary between those who made all the observer choices after the relevant Social Risk and Personal Risk
decisions? The analog for Proposition 4 is to focus on whether the observer choices came after the Social Risk and
Social Choice choices.

```{r echo=FALSE, message=FALSE, warning=FALSE}
# loading the key test datasets and merge them to the sequence data:

tar_load("p3_00")
tar_load("selfish")
prop3_ps <- map_dfr( keep(p3_00, function(x) (x$id %in% selfish$id)),
                     function(x) tibble(id=x$id, p= x$p_com)) 
prop3_ordered <- ordered_means %>% 
  filter(treatment=="dictator") %>%
  right_join(prop3_ps) %>% 
  mutate(observer_at_end = ifelse( (DRO_order %in% c("2,3,4","3,2,4","4,2,3")), "Observer choices at end", "Observer choices in between"))

tar_load("p4_00")
tar_load("symmetric")
prop4_ps <- map_dfr( keep(p4_00, function(x) (x$id %in% symmetric$id)),
                     function(x) tibble(id=x$id, p= x$p_com)) 
prop4_ordered <- ordered_means %>% 
  filter(treatment=="dictator") %>%
  right_join(prop4_ps) %>% 
  mutate(observer_at_end = ifelse( (DRO_order %in% c("2,3,4","2,4,3","3,2,4")), "Observer choices at end", "Observer choices in between"))
```


We can now run tests on whether the p-values are affected by whether there are observer choices mixed in or not,
and we can look at the graphs by this condition. First for Proposition 3, then for proposition 4.
```{r echo=FALSE, message=FALSE, warning=FALSE}
(observer_test <- wilcox.test(p ~ observer_at_end, data=prop3_ordered))
caption_text <- paste("P-value of Wilcoxon rank sum test on equality of location: ", 
                      format(observer_test$p.value, digits=3))
prop3_ordered %>% ggplot(aes(x=p, y = (..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..]) ) + 
  geom_histogram(binwidth=0.05, boundary=0) + 
  theme_minimal() +
  theme(plot.title.position = "plot") +
  facet_wrap(.~observer_at_end, dir="v") +
  labs(x = "Combined p-value", y ="Fraction of individuals",
       title = "Is there an influence of observer choices on SR = PR (on the selfish)?",
       caption=caption_text)
ggsave(here::here("graphs","observer_choices_proposition3.pdf"),width=16, height = 20, units = "cm")
```
```{r echo=FALSE, message=FALSE, warning=FALSE}
(observer_test <- wilcox.test(p ~ observer_at_end, data=prop4_ordered))
caption_text <- paste("P-value of Wilcoxon rank sum test on equality of location: ", 
                      format(observer_test$p.value, digits=3))
prop4_ordered %>% ggplot(aes(x=p, y = (..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..]) ) + 
  geom_histogram(binwidth=0.05, boundary=0) + 
  theme_minimal() +
  theme(plot.title.position = "plot") +
  facet_wrap(.~observer_at_end, dir="v") +
  labs(x = "Combined p-value", y ="Fraction of individuals",
       title = "Is there an influence of observer choices on the SC=SR (symmetric)?",
       caption=caption_text)
ggsave(here::here("graphs","observer_choices_proposition3.pdf"),width=16, height = 20, units = "cm")
```

But remember that there are only 19 symmetric individuals to start with.


Another perspective is to ask if there is any joint effect on the average choices by 
the possible sequences of the treatments, a more general
test of sequence effects.

First for risk, we test 
the share allocated the cheapest asset by sequence (all six sequences):
```{r echo=FALSE}
ordered_means %>% filter(treatment=="risk") %>%
  kruskal.test(share_cheapest ~ DRO_order, data=.)
```
Now for "Social Choice", we look at the share taken for self:
```{r}
ordered_means %>% filter(treatment=="dictator") %>%
  kruskal.test(share_self ~ DRO_order, data=.) 
```
And for the observer choice itself (not used in the paper):
```{r}
ordered_means %>% filter(treatment=="observer") %>%
  kruskal.test(share_cheapest ~ DRO_order, data=.) 
```


# Symmetry

Referee 3 brings up the question of *testing* for symmetry instead of the
restriction on average share vs. the simple criterion we use (which is that the
average share of tokens taken for self is $0.50\pm 0.05$).

How to think about testing for symmetry? 
We develop a non-parametric test for symmetry along the lines of our test for equality of preferences. This will be based on the fact that the mirror image of any actual budget set was equally likely as the realized
budget set, and that under the symmetry hypothesis, we know that the *choice* would have been the mirror
image of the actual choice. So the realized choices and budgets is one out of $2^{50}$ possible combinations, and we can see if the realized CCEI is in the far right tail of this simulated CCEI-distribution, in which
case we reject the null hypothesis of symmetry (so, a one-sided test). BTW: This seems a useful application of some general interest in itself, since we don't need to restrict the design of the original budget sets. 
This creates a stochastic version of the symmetry test of Chambers and Rehbeck (Economics Letters 2018) that does not test symmetry **and** GARP. 


## Non-parametric symmetry test: Distribution of p-values on "symmetry" in each domain
For completeness, here is the distribution of "symmetry" p-values for all
individuals in all three domains:

```{r echo=FALSE, message=FALSE, warning=FALSE}
tar_load("symmetricp_dict")
tar_load("symmetricp_moral")
tar_load("symmetricp_risk")
sym1 <- symmetricp_dict %>% map_df( function(x) tibble(id = x$id, psymmetric = x$p, treatment="Social Choice") )
sym2 <- symmetricp_moral %>% map_df( function(x) tibble(id = x$id, psymmetric = x$p, treatment="Social Risk") )
sym3 <- symmetricp_risk %>% map_df( function(x) tibble(id = x$id, psymmetric = x$p, treatment="Personal Risk") )
symmetry_df <- list(sym1,sym2,sym3) %>% bind_rows() %>%
  mutate(treatmentf = factor(treatment, levels=c("Social Choice", "Personal Risk", "Social Risk")))
symmetry_df %>% ggplot(aes(x=psymmetric, y = (..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..])) +
  geom_histogram(binwidth=0.05, boundary = 0) +
  theme_minimal() +
  labs(x="P-value on H0: Symmetry", 
       y="Fraction of participants") +
  facet_wrap(.~treatmentf, dir="v") 
ggsave(here::here("graphs","symmetry_3_treatments.pdf"), width = 16, height = 20, units = "cm")
```

As we should expect, symmetry is rejected for almost all in the "Social" domain, but for almost none
in the "Personal Risk" and "Social risk" domains.

Note that "symmetric" just means that the null-hypothesis of "symmetry" is not
rejected. 

## How different is the non-parametric symmetry test from our simplified criterion?

Our main criterion for impartiality is that the share of tokens for self in the
Social Choice environment is within  $0.5\pm 0.05$. To see how well
these criteria agree, we plot the p-value from the non-parametric test vs the 
average share of tokens taken from self. 

```{r echo=FALSE, message=FALSE, warning=FALSE}
tar_load("symmetricp_dict")
symmetricp_df <- symmetricp_dict %>% map_df( function(x) tibble(id = x$id, psymmetric = x$p) )
symmetric_evaluation <- mmzame_decisions %>% filter(treatment=="dictator") %>% 
  mutate(yshare = y/(x+y)) %>%
  group_by(id) %>%
  summarize(share_self = mean(yshare)) %>% left_join(symmetricp_df) 
symmetric_evaluation %>% ggplot(aes(x=share_self, y=psymmetric)) +
  geom_rect(aes(xmin=0.45,
                xmax=0.55,
                ymin=0, 
                ymax=1.05
  ), fill="grey90") +
    geom_point(alpha=0.25) +
  theme_minimal() + 
  labs(x="Mean share of tokens taken for self",
       y="P-value on H0: Symmetry in Social Choice")
ggsave(here::here("graphs","symmetrytest_vs_simplecriterion.pdf"), width = 16, height = 10, units = "cm")
```

We can look at the overlap of the two dimensions. First extract
the ids of those that we classified as impartial.
```{r}
impartials <- symmetric_evaluation$id[ symmetric_evaluation$share_self>0.45 & symmetric_evaluation$share_self<0.55]
impartials
symmetrics <- symmetric_evaluation$id[ symmetric_evaluation$psymmetric>0.05]
symmetrics

intersect(impartials, symmetrics)

setdiff(impartials, symmetrics)
setdiff(symmetrics, impartials)

symmetric_evaluation |> filter(share_self>0.6 & psymmetric>0.05)

```





We see that for the most part, all selfish individuals (and the very generous)
generate clear rejections of symmetry, while for those within the light grey
band (classified as symmetric in the main paper) we mostly cannot reject
symmetry. Note that we also cannot reject symmetry for a handful of individuals
that have fairly large shares of tokens for themselves on average (so they
would seem to implement an intermediate level of selfishness). These are
individuals that are not very consistent to begin with (they seem
to behave very randomly), and the nonparametric symmetry test has little power for 
such participants.



# Referee 3, point 2.


```{r echo=FALSE, message=FALSE, warning=FALSE}
tar_load(p2_00)
tar_load(p3_00)
tar_load(p4_00)
self_shares <- mmzame_decisions %>% 
  filter(treatment=="dictator") %>%
  mutate(share_self = y/(x+y)) %>%
  group_by(id) %>%
  summarize(mean_share_self = mean(share_self))
prop3_ps <- map_dfr( p3_00, function(x) tibble(id=x$id, p= x$p_com, comparison="Social Risk vs. Personal Risk")) 
prop2_ps <- map_dfr( p2_00, function(x) tibble(id=x$id, p= x$p_com, comparison="Personal Risk vs. Social Choice")) 
prop4_ps <- map_dfr( p4_00, function(x) tibble(id=x$id, p= x$p_com, comparison="Social Risk vs. Social Choice")) 
all_tests <- list(prop3_ps, prop2_ps, prop4_ps) %>% 
  bind_rows() %>% left_join(self_shares) %>% mutate(selfish = (mean_share_self> 0.95),
                                                    selfishf = factor(ifelse(selfish,"Selfish","Not Selfish"), levels=c("Selfish", "Not Selfish")),
                                                    impartialf = factor(ifelse(abs(mean_share_self-0.5)<0.05, "Impartial", "Not Impartial"), levels=c("Impartial", "Not Impartial")))
R3_2 <- all_tests %>% 
  filter(comparison == "Social Risk vs. Personal Risk") |>
  ggplot(aes(x=p, y = (..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..])) +
  geom_histogram(binwidth=0.05, boundary=0) +
  theme_minimal() +
  facet_grid(. ~selfishf) +
  labs( y = "Fraction of participants",
        x = "P-value on H0: Equality of preferences")
R3_2
ggsave(here::here("graphs","R3_2.pdf"), width = 16, height = 10, units = "cm")
```

# Referee 3, point 1: 

```{r echo=FALSE, message=FALSE, warning=FALSE}
all_tests_symmetric <- list(prop3_ps, prop2_ps, prop4_ps) %>% 
  bind_rows() %>% left_join(self_shares) %>% mutate(symmetric = abs(mean_share_self-0.5)<0.05,
                                                    symmetricf = factor(ifelse(symmetric,"Impartial","Not Impartial")))
R3_1 <- all_tests_symmetric %>% 
  filter(comparison == "Personal Risk vs. Social Choice") |>
  ggplot(aes(x=p, y = (..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..])) +
  geom_histogram(binwidth=0.05, boundary=0) +
  theme_minimal() +
  facet_grid(.~symmetricf) +
  labs( y = "Fraction of participants",
        x = "P-value on H0: Equality of preferences")
R3_1
ggsave(here::here("graphs","R3_1.pdf"), width = 16, height = 10, units = "cm")

```


All cases, for the symmetric/non-symmetric with the non-parametric (Social Choice domain) definition:

```{r echo=FALSE, message=FALSE, warning=FALSE}

alternative_symmetric_subset <- sym1 |> filter(psymmetric>0.05) 
all_tests_alternative_symmetric <- all_tests_symmetric |> 
  mutate(alternative_symmetricf = factor(ifelse(id %in% alternative_symmetric_subset$id, "Symmetric", "Not Symmetric"), 
                                         levels=c("Symmetric", "Not Symmetric")))

all_tests_alternative_symmetric |> 
ggplot(aes(x=p, y = (..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..])) +
  geom_histogram(binwidth=0.05, boundary=0) +
  theme_minimal() +
  facet_grid(comparison~alternative_symmetricf) +
  labs( y = "Fraction of participants",
        x = "P-value on H0: Equality of preferences")
ggsave(here::here("graphs","equality_by_symmetry_3domains.pdf"), width=16, height=20, units="cm")



```

Now the same graph, but with the paper's impartial definition.
```{r}
all_tests |> 
ggplot(aes(x=p, y = (..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..])) +
  geom_histogram(binwidth=0.05, boundary=0) +
  theme_minimal() +
  facet_grid(comparison~impartialf) +
  labs( y = "Fraction of participants",
        x = "P-value on H0: Equality of preferences")
ggsave(here::here("graphs","equality_by_symmetry_3domains_impartial.pdf"), width=16, height=20, units="cm")
```




We were going over different ways to present these results. Please let me know if 
there are other views you would prefer. 

## 3-way test across all domains

It is straightforward to generalize from drawing decisions from one out of two
domains to drawing them from K different domains. Of course, the distribution 
of the test statistic changes, but in general 
from K draws,
$e_1,e_2,\dots,e_K$, we can define $e^{+}=\max_k e_k$ and
$e^{-} = \min_k e_k$ and the $p$-values can be calculated
from a permutation distribution $\widehat{F}$ 
as 
$$\begin{align*} p_{e^{+}} &= P(\max_k e_k \geq e^{+}), \\
&= 1 - P(\max_k e_k < e^{+}), \\
&= 1 - P(e_1 < e^{+}, e_2 < e^{+}, \dots, e_K < e^{+}), \\
&= 1 - \left(P(e_1 < e^{+}) \cdot P(e_2< e^{+}) \cdot \ldots \cdot P(e_K<e^{+})\right),\\
&= 1 - \left(\lim_{\epsilon \uparrow 0}F(e^{+}-\epsilon)\right)^K, \\
&\approx 1-\left(\widehat{F}(e^{+}-\varepsilon)\right)^K.
\end{align*}$$
for a $\varepsilon$ chosen to be a number close to zero. 

Similarly for the minimum statistic: 
$$\begin{align*} p_{e^{-}} &= P(\min_k e_k \geq e^{-}), \\
&= P(e_1\geq e^{-}, e_2\geq e^{-}, \dots, e_K\geq e^{-}), \\
&= \left(1-P(e_1<e^{-})\right)\cdot\left(1-P(e_2<e^{-})\right)\cdot \ldots \cdot \left(1-P(e_K<e^{-})\right),\\
&= \left(1- \lim_{\epsilon\uparrow 0}F(e^{-}-\epsilon)\right)^K, \\
&\approx \left(1-\widehat{F}(e^{-}-\varepsilon)\right)^K.
\end{align*}$$
also for a small $\varepsilon$.

We are still interested in rejections which take the form of realizations being in the
right tail of this distribution (more consistent within than between domains), and
implement with a small $\varepsilon$ offset because the permutation distributions of $\widehat{F}$
are lumpy.  We have coded this up as a general function that takes a list of choice data
frames as an argument, and which takes care of learning K from the length of this list.

We can look at the distribution of p-values in the test
that preferences are the same in all of the three domains: Social, Social Risk, and Personal Risk.  

The data comes in the form of a list (keeping all the permuted CCEI values), so
they need to be extracted to form a data frame for graphing.
```{r echo=FALSE, message=FALSE, warning=FALSE}
tar_load("pall_domains")
allp_df <- pall_domains %>% map(function(X) 
  tibble(id=X$id, p_min=X$p_min, p_max=X$p_max, p_com = X$p_com)) %>%
  bind_rows()
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
allp_with_symmetry_df <- allp_df |> 
  mutate(symmetric_alternativef = factor(ifelse(id %in% alternative_symmetric_subset$id, "Symmetric", "Not Symmetric"), levels=c("Symmetric","Not Symmetric")))

allp_with_symmetry_df |> ggplot(aes(x = p_com, 
                       y = (..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..])) + 
  geom_histogram(binwidth=0.05, boundary=0) +
  theme_minimal() +
  labs(x = "P-value on H0: Equality of preferences",
       y = "Fraction of participants") +
  facet_grid(. ~symmetric_alternativef)
ggsave(here::here("graphs","equality_of_preferences.pdf"), width=16, height=10, unit = "cm")
```


Now with the simple definition of symmetric:
```{r echo=FALSE, message=FALSE, warning=FALSE}
symmetric_subset <- all_tests_symmetric |> filter(symmetric)
allp_with_simple_symmetry_df <- allp_df |> 
  mutate(impartial = factor(ifelse(id %in% symmetric_subset$id, "Impartial", "Not Impartial"), levels=c("Impartial", "Not Impartial")))
allp_with_simple_symmetry_df |> ggplot(aes(x = p_com, 
                       y = (..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..])) + 
  geom_histogram(binwidth=0.05, boundary=0) +
  theme_minimal() +
  labs(x = "P-value on H0: Equality of preferences",
       y = "Fraction of participants") +
  facet_grid(. ~impartial)
ggsave(here::here("graphs","equality_of_preferences_impartial.pdf"), width=16, height=10, unit="cm")

```


## All individuals, broken down by selfishness


```{r echo=FALSE, message=FALSE, warning=FALSE}
all_tests_selfish <- list(prop3_ps, prop2_ps, prop4_ps) %>% 
  bind_rows() %>% left_join(self_shares) %>% mutate(selfish = mean_share_self>0.95,
                                                    selfishf = factor(ifelse(selfish,"Selfish","Not Selfish"), levels=c("Not Selfish", "Selfish")))
all_comparisons_selfish <- all_tests_selfish %>% 
  ggplot(aes(x=p, y = (..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..])) +
  geom_histogram(binwidth=0.05, boundary=0) +
  theme_minimal() +
  facet_grid(comparison~selfishf) +
  labs( y = "Fraction of participants",
        x = "P-value on H0: Equality of preferences")
all_comparisons_selfish
ggsave(here::here("graphs","all_comparisons_selfish.pdf"), width = 16, height = 20, units = "cm")
```

## The subsets testing propositions
```{r}
allp2 <- all_tests_selfish |> filter(selfish==TRUE, comparison == "Social Risk vs. Personal Risk" ) |>
  ggplot(aes(x=p, y = (..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..])) +
  geom_histogram(binwidth=0.05, boundary=0) +
  theme_minimal() +
  labs( y = "Fraction of participants",
        x = "P-value on H0: Equality of preferences",
        title = "Proposition 2")
allp3 <- all_tests_selfish |>  
  mutate(impartial = factor(ifelse(id %in% symmetric_subset$id, "Impartial", "Not Impartial"), 
                            levels=c("Impartial", "Not Impartial"))) |>
  filter(impartial=="Impartial", comparison == "Social Risk vs. Social Choice") |>
  ggplot(aes(x=p, y = (..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..])) +
  geom_histogram(binwidth=0.05, boundary=0) +
  theme_minimal() +
  labs( y = "Fraction of participants",
        x = "P-value on H0: Equality of preferences",
        title = "Proposition 3")

allp2 + allp3 +   plot_annotation(tag_levels = "a")
```
